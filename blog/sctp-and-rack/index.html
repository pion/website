<!doctype html><html><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>RACK makes Pion SCTP 71% faster with 27% less latency | Pion</title><meta name=description content="In the RACK profile, SCP sustained 316 Mbps using ~0.044 CPU seconds, compared to 234 Mbps at ~0.056 CPU seconds before RACK. When normalized for CPU usage, this corresponds to a ~71% improvement in throughput per CPU, while max-burst CPU profiles remain comparable."><link rel="shortcut icon" type=image/png href=data:image/png;base64,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><link href="https://fonts.googleapis.com/css?family=Quicksand" rel=stylesheet><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/bulma/0.7.4/css/bulma.min.css><link href=/css/main.css rel=stylesheet><script async defer src=https://buttons.github.io/buttons.js></script><script defer src=https://use.fontawesome.com/releases/v6.7.2/js/all.js></script><script src=/js/bulma-menu.js></script><script src=/js/knowledge-base-sidebar.js></script><script src=/js/triage.js></script><script src=/js/tinybind.js></script></head><body><nav class="navbar is-black" role=navigation aria-label="main navigation"><div class=navbar-brand><a class=navbar-item href=/><img src=/img/pion-logo.svg width=112 height=28>
</a><a class="navbar-item is-hidden-desktop" href=https://github.com/pion target=_blank><span class=icon><i class="fab fa-github"></i>
</span></a><a class="navbar-item is-hidden-desktop" href=https://x.com/_pion target=_blank><span class=icon><i class="fab fa-x-twitter"></i>
</span></a><a class="navbar-item is-hidden-desktop" href=https://bsky.app/profile/pion.ly target=_blank><span class=icon><i class="fab fa-bluesky"></i>
</span></a><a class="navbar-item is-hidden-desktop" href=https://discord.gg/6EsQz85vPE target=_blank><span class=icon><i class="fab fa-discord"></i>
</span></a><a role=button class="navbar-burger burger" aria-label=menu aria-expanded=false data-target=navbarMenuItems><span aria-hidden=true></span>
<span aria-hidden=true></span>
<span aria-hidden=true></span></a></div><div id=navbarMenuItems class=navbar-menu><div class=navbar-start><a class=navbar-item href=/blog/>Blog
</a><a class=navbar-item href=/why-pion/>Why Pion
</a><a class=navbar-item href=https://github.com/pion/awesome-pion>awesome-pion
</a><a class=navbar-item href=https://webrtcforthecurious.com>WebRTC for the Curious
</a><a class=navbar-item href=https://siobud.com/meeting>Office Hours
</a><a class=navbar-item href=/triage/>Triage</a></div><div class=navbar-end><div class=navbar-item><div class="buttons is-hidden-touch"><a class="navbar-item navbar-item-desktop" href=https://github.com/pion target=_blank><span class=icon><i class="fab fa-github"></i>
</span></a><a class="navbar-item navbar-item-desktop" href=https://x.com/_pion target=_blank><span class=icon><i class="fab fa-x-twitter"></i>
</span></a><a class="navbar-item navbar-item-desktop" href=https://bsky.app/profile/pion.ly target=_blank><span class=icon><i class="fab fa-bluesky"></i>
</span></a><a class="navbar-item navbar-item-desktop" href=https://discord.gg/6EsQz85vPE target=_blank><span class=icon><i class="fab fa-discord"></i></span></a></div></div></div></div></nav><main><section><div class="columns has-text-centered" style=padding-top:3em><div class=column><h1 class=title style=font-size:3rem>RACK makes Pion SCTP 71% faster with 27% less latency</h1><p>In the RACK profile, SCP sustained 316 Mbps using ~0.044 CPU seconds, compared to 234 Mbps at ~0.056 CPU seconds before RACK. When normalized for CPU usage, this corresponds to a ~71% improvement in throughput per CPU, while max-burst CPU profiles remain comparable.</p><p>R Chiu, Joe Turki -- 2025-12-21</p><hr class=pion-hr></div></div></section><section><div class=content style=padding:3em><h2 id=what-is-sctp>What is SCTP?<a class=content-header-href href=#what-is-sctp><i class="fas fa-paperclip"></i></a></h2><p>SCTP stands for Stream Control Transmission Protocol. At a basic level, SCTP is designed to be reliable, handle de-duplication of packets, and support packets that may be delivered in order or out of order. Beyond transporting messages, SCTP can also set up a connection between users. On a deeper level, SCTP includes native support for multiplexing: multiple applications can take advantage of a single transport connection. SCTP also supports multi-homing, which enables automatic failover from a primary connection to a secondary one.</p><p>At the most basic level, it lets you reliably send information from one computer to another without any complications.</p><h3 id=what-is-sctp-used-for>What is SCTP used for?<a class=content-header-href href=#what-is-sctp-used-for><i class="fas fa-paperclip"></i></a></h3><p>SCTP&rsquo;s uses can generally fit into two cases:</p><h4 id=1-sending-some-amount-of-data>1. Sending some amount of data.<a class=content-header-href href=#1-sending-some-amount-of-data><i class="fas fa-paperclip"></i></a></h4><p>Imagine a scenario where two people are texting when one person remembers a picture that they want to send. As they text back and forth, an image gets uploaded, which takes some time to get sent. SCTP can handle multiple things going on at the same time and doesn&rsquo;t delay any messages from being sent just because an image is being uploaded! Thanks to SCTP, text messages can be safely delivered to each person and nothing in their conversation is lost in transit or delayed just because something else is being transferred at the same time as their messages.</p><p>Building on this idea, users can share larger files with each other. This includes anything: birthday videos, audio recordings, even boring paperwork; anything that&rsquo;s a file can be sent!</p><h4 id=2-sending-small-amounts-of-data-with-a-purpose>2. Sending small amounts of data with a purpose.<a class=content-header-href href=#2-sending-small-amounts-of-data-with-a-purpose><i class="fas fa-paperclip"></i></a></h4><p>In a new scenario, imagine two people who are texting back and forth when one person gets hungry. They send a message saying, &ldquo;I want a pizza!&rdquo; When the other person receives the text, they think, &ldquo;Maybe I should do something about that!&rdquo; The recipient can choose to do something useful for the sender with that information.</p><p>This is the blueprint for many awesome technologies today, as it opens up the possibility of controlling one computer from a different computer. Consider a surgeon who performs an operation involving a remote-controlled device that needs to respond with as little latency as possible. Similarly, real-time navigation systems also need to respond to changes in traffic conditions quickly in order to avoid congested or unsafe areas due to accidents or weather conditions.</p><h4 id=other-uses>Other uses:<a class=content-header-href href=#other-uses><i class="fas fa-paperclip"></i></a></h4><p>SCTP can be used for online multiplayer games where every frame counts, including first-person shooters and fighting games. Taking the remote surgery example in this direction leads to the idea of cloud gaming, as players can have their inputs sent to a different device than the one that they&rsquo;re using while still being able to play the game!</p><p>SCTP is also used inside web browsers via WebRTC and has found use in AI applications and cryptocurrency-related technologies. Additionally, payment verification can similarly benefit from secure and fast communication.</p><h2 id=why-sctp-for-webrtc>Why SCTP for WebRTC?<a class=content-header-href href=#why-sctp-for-webrtc><i class="fas fa-paperclip"></i></a></h2><p>SCTP is used for WebRTC because of its ability to send information via reliable and unreliable datachannels. For example, you can send messages or files in a chat with SCTP. Other uses include being able to know when users toggle their microphone or video in a video call. In some special cases, SCTP can even be used to transmit video between users, but that&rsquo;s significantly less common.</p><p>In WebRTC, the ICE protocol connects users and the DTLS protocol establishes a secure connection, at which point SCTP is then used to securely transfer data. In an ideal setup, data that&rsquo;s sent should &ldquo;just work&rdquo;. Unfortunately, that isn&rsquo;t how things tend to pan out, as issues eventually crop up. Packets get dropped, the network jitters, the computer stutters, or the coffee machine doesn&rsquo;t start when you thought it had. That&rsquo;s why it&rsquo;s important to have a backup plan for when things go wrong.</p><h2 id=how-sctp-deals-with-loss>How SCTP Deals With Loss<a class=content-header-href href=#how-sctp-deals-with-loss><i class="fas fa-paperclip"></i></a></h2><p>SCTP was designed with this in mind and has two built-in recovery strategies for when networking goes wrong.</p><p>The first is called &ldquo;fast retransmission.&rdquo; The receiver detects if a chunk of data is missing in the transmission. If so, the receiver notifies the sender that a specific chunk ID is missing. If the sender receives three reports of a missing chunk where all three reports are referring to the same chunk ID, then the sender will assume that the chunk has been lost and resend it.</p><p>The second is a timer-based retransmission. This happens if the receiver doesn&rsquo;t acknowledge that it has received all the packets within a specific window of time. If the receiver doesn&rsquo;t acknowledge that all the packets have been received, then the sender is prompted to retransmit the unacknowledged data.</p><p>Both of these loss recovery strategies are used by SCTP to try to ensure that any lost data is detected and retransmitted as quickly as possible. At the time of writing, Pion&rsquo;s implementation of <a href=https://github.com/pion/sctp/tree/b1a66a4>Pion&rsquo;s implementation of SCTP</a> uses these two mechanisms for loss recovery.</p><p>These strategies are also used by TCP, which has prompted engineers to see if there&rsquo;s an even better strategy to detect and mitigate lost data.</p><h2 id=introducing-rack>Introducing RACK<a class=content-header-href href=#introducing-rack><i class="fas fa-paperclip"></i></a></h2><p>In February 2021, <a href=https://www.rfc-editor.org/rfc/rfc8985.html>RFC 8985: The RACK-TLP Loss Detection Algorithm for TCP</a> was published. This was a completely new loss detection algorithm that focused on actively keeping track of network statistics and using timer-based signals in order to remain adaptive to ever-changing network conditions. RACK&rsquo;s improvements over SACK and fast retransmission in TCP were enticing enough for Linux, Windows, and FreeBSD to all implement it in TCP.</p><p>While RACK was originally intended to be implemented for TCP, it is <a href=https://www.rfc-editor.org/rfc/rfc8985.html#section-9.5>noted in the RFC that it can be implemented in other transport protocols</a>, including SCTP.</p><p>The implementation for SCTP was formally analyzed in <a href=https://duepublico2.uni-due.de/servlets/MCRFileNodeServlet/duepublico_derivate_00073893/Diss_Weinrank.pdf>Felix Weinrank&rsquo;s Dissertation</a> and other publications. Weinrank&rsquo;s deep dive provides an extremely comprehensive review of SCTP and improvements regarding usage in various scenarios, including WebRTC. At the moment, we&rsquo;re more concerned with Weinrank&rsquo;s analysis and implementation notes regarding RACK in SCTP. In <a href=https://duepublico2.uni-due.de/servlets/MCRFileNodeServlet/duepublico_derivate_00073893/Diss_Weinrank.pdf#chapter.192>Chapter 7 of the dissertation</a>, Weinrank goes over how SCTP handles loss and how RACK can be implemented for SCTP, including extra details regarding how the implementation interacts with various SCTP extensions.</p><h2 id=racks-motivations>RACK&rsquo;s motivations:<a class=content-header-href href=#racks-motivations><i class="fas fa-paperclip"></i></a></h2><p>The authors of RACK in <a href=https://www.rfc-editor.org/rfc/rfc8985.html>RFC 8985</a> provides examples of situations where RACK improves SCTP and TCP during loss recovery.</p><h3 id=how-racks-tail-loss-probing-tlp-works>How RACK&rsquo;s Tail Loss Probing (TLP) Works<a class=content-header-href href=#how-racks-tail-loss-probing-tlp-works><i class="fas fa-paperclip"></i></a></h3><pre class=mermaid>
  sequenceDiagram
    participant S as Sender
    participant R as Receiver

    Note over S,R: The two sends are normally&lt;br&gt;combined but are separated&lt;br&gt;here for visual clarity.
    S-&gt;&gt;R: Send ğŸ
    S--&gt;&gt;R: Send ğŸŒ, ğŸ¥•, ğŸ¥”
    Note right of R: Only ğŸ arrived, so it&#39;s ACK&#39;d.
    R-&gt;&gt;S: ACK ğŸ

    Note over S,R: 2 RTTs later, TLP fires
    S-&gt;&gt;R: TLP triggers a retransmit ğŸ¥”
    Note right of R: ğŸ¥” arrived, so it&#39;s SACK&#39;d.
    R-&gt;&gt;S: SACK ğŸ¥”

    Note left of S: Mark ğŸŒ and ğŸ¥• as lost
    Note over S,R: The two sends are normally&lt;br&gt;combined but are separated&lt;br&gt;here for visual clarity.
    S--&gt;&gt;R: Retransmit ğŸŒ
    S-&gt;&gt;R: Retransmit ğŸ¥•
    Note right of R: Only ğŸ¥• arrived, so it&#39;s SACK&#39;d&lt;br&gt;alongside ğŸ¥”.
    R--&gt;&gt;S: SACK ğŸ¥• and ğŸ¥”

    Note left of S: ğŸŒ retransmission marked as lost.&lt;br&gt;Note that this is the second time&lt;br/&gt;that ğŸŒ has been marked as lost.
    S-&gt;&gt;R: Retransmit ğŸŒ again
    Note right of R: ğŸŒ finally arrived!
    R--&gt;&gt;S: ACK ğŸ¥”
    Note over S,R: The ACK ğŸ¥” is a cumulative ACK&lt;br&gt;for the ğŸğŸŒğŸ¥•ğŸ¥” sequence
</pre><p>In the above scenario, Tail Loss Probing enables the sender to quickly know if ğŸğŸŒğŸ¥•ğŸ¥” were successfully received. Since the sender only receives an acknowledgment (ACK) for ğŸ from the receiver, the TLP timer eventually triggers because it didn&rsquo;t receive an ACK for ğŸŒ, ğŸ¥•, and ğŸ¥”. The TLP can then resend the last packet in the segment as an efficient way to:</p><ol><li><p>Retransmit data that the receiver would have to receive down the line anyway. The alternative would be to send an empty packet, receive an ACK, then send a missing packet. This handles both at once and can potentially save an RTT if <em>only</em> the last packet is missing in a segment.</p></li><li><p>Allow the receiver to ACK any earlier missing packets in the sequence if there were other issues due to networking, temporary stutters or freezes, etc.</p></li><li><p>Check receiver responsiveness and detect if there&rsquo;s a network issue. Note that this is different from (2), as the receiver could potentially never respond with an ACK.</p></li></ol><p>The receiver then confirms that it has ğŸ¥” by sending a selective acknowledgment (SACK) to the sender, which tells the sender that it&rsquo;s received one of the packets from the segment but not all of them. At this point, the sender has an ACK for ğŸ and a SACK for ğŸ¥”, which means that it can determine that ğŸŒ and ğŸ¥• must be missing. The sender then notes that ğŸŒ and ğŸ¥• have been lost once. It then retransmits ğŸŒ and ğŸ¥•. In the example, ğŸŒ happens to get dropped by the network whereas ğŸ¥• is sent and received successfully. The receiver then replies with a SACK for ğŸ¥• and ğŸ¥”, at which point the sender can determine that ğŸŒ was lost a second time. Finally, the sender retransmits ğŸŒ, which fortunately doesn&rsquo;t get dropped, and the receiver sends an ACK for ğŸ¥” (note the ACK is for the last packet in the segment, which implies that all previous packets have been received).</p><p>Side note: keeping track of the number of times that a packet has been lost is important as the cubic congestion control algorithm described in <a href=https://datatracker.ietf.org/doc/rfc9438/>RFC 9438</a> (which is mentioned in RFC 8985) relies on this information.</p><h3 id=sctp-rto-vs-rack-rto>SCTP RTO vs RACK RTO<a class=content-header-href href=#sctp-rto-vs-rack-rto><i class="fas fa-paperclip"></i></a></h3><p>In this example, the authors of <a href=https://www.rfc-editor.org/rfc/rfc8985.html>RFC 8985</a> show how, without RACK, SCTP and TCP can suffer from spurious retransmissions when there are retransmission timeouts (RTOs). In this case, each food icon represents an entire segment instead of a packet.</p><pre class=mermaid>
  sequenceDiagram
    participant S as Sender
    participant R as Receiver

    S-&gt;&gt;R: Send ğŸ¥
    Note over S,R: Then right before&lt;br&gt;the end of the RTO...
    Note right of R: The receiver has a network hiccup!
    S-&gt;&gt;R: Send ğŸ³ğŸ¥­

    Note right of R: Received ğŸ¥
    Note over S,R: End of the RTO
    R-&gt;&gt;S: ACK ğŸ¥
</pre><p>In this scenario, ğŸ¥ is sent, and right before the end of the RTO, ğŸ³ and ğŸ¥­ are sent. The receiver gets ğŸ¥, ğŸ³, and ğŸ¥­, but only manages to send an ACK for ğŸ¥ right after the RTO. Let&rsquo;s see how SCTP handles this without RACK versus with RACK.</p><pre class=mermaid>
  sequenceDiagram
    participant S as Sender
    participant R as Receiver

    S-&gt;&gt;R: Send ğŸ¥
    Note over S,R: Then right before&lt;br&gt;the end of the RTO...
    Note right of R: The receiver has a network hiccup!
    S-&gt;&gt;R: Send ğŸ³ğŸ¥­

    Note right of R: Received ğŸ¥
    Note over S,R: End of the RTO
    R-&gt;&gt;S: ACK ğŸ¥

    Note over S,R: Without RACK...

    %% without rack
    Note left of S: Mark ğŸ¥ğŸ³ğŸ¥­ as lost&lt;br&gt;since RTO expired

    Note right of R: Received ğŸ³ğŸ¥­
    Note over S,R: The Sender incorrectly&lt;br&gt;ignores the ack for ğŸ³ğŸ¥­!

    Note left of S: Prepare to retransmit ğŸ¥ğŸ³ğŸ¥­
    S-&gt;&gt;R: Retransmit ğŸ¥ğŸ³ğŸ¥­
</pre><p>We can see here that the receiver eventually sends an ACK for ğŸ³ and ğŸ¥­, but the sender ignores it and believes that ğŸ¥, ğŸ³, and ğŸ¥­ are all missing instead of just ğŸ¥. While it&rsquo;s reasonable to assume that ğŸ¥ is missing, it&rsquo;s a little overzealous in retransmitting packets, which can increase network traffic during recovery, especially when it&rsquo;s completely possible for the sender to wait for the acknowledgments of ğŸ³ and ğŸ¥­ from the receiver.</p><p>Let&rsquo;s see what RACK does!</p><pre class=mermaid>
  sequenceDiagram
    participant S as Sender
    participant R as Receiver

    S-&gt;&gt;R: Send ğŸ¥
    Note over S,R: Then right before&lt;br&gt;the end of the RTO...
    Note right of R: The receiver has a network hiccup!
    S-&gt;&gt;R: Send ğŸ³ğŸ¥­

    Note right of R: Received ğŸ¥
    Note over S,R: End of the RTO
    R-&gt;&gt;S: ACK ğŸ¥
    Note over S,R: With RACK...

    %% with rack
    Note left of S: Mark ğŸ¥ as lost&lt;br&gt;since RTO expired

    Note right of R: Received ğŸ³ğŸ¥­

    Note left of S: Prepare to retransmit ğŸ¥
    S-&gt;&gt;R: Retransmit ğŸ¥
</pre><p>Here, RACK makes it so only ğŸ¥ is marked as lost when the RTO expires. ğŸ³ and ğŸ¥­ aren&rsquo;t marked as lost because their own RTOs have not yet expired by the time their ACKs are received. Therefore, only ğŸ¥ is retransmitted, as the timers for ğŸ³ and ğŸ¥­ would be re-armed if an ACK is received for the retransmitted ğŸ¥.</p><p>In this example, even though both non-RACK and RACK end up retransmitting ğŸ¥ despite the receiver already having it, the focus is on minimizing spurious retransmissions. This can save on the amount of data sent over the network, which naturally speeds up any retransmissions that might occur.</p><h3 id=racks-strategy>RACK&rsquo;s strategy<a class=content-header-href href=#racks-strategy><i class="fas fa-paperclip"></i></a></h3><p>In summary, RACK&rsquo;s strategy generally has two main parts:</p><ol><li><p>Detect packet losses as quickly as possible by utilizing time-based acknowledgments of segmented data and inferences from network statistics.</p></li><li><p>Use Tail Loss Probing (TLP), which sends sample data to gather more network statistics.</p></li></ol><p>The combination of these two strategies allows it to quickly determine issues and properly rectify them once identified. It also provides better resilience for some tricky edge cases! If you&rsquo;re interested in seeing how RACK could perform in SCTP and other SCTP-specific improvements, check out <a href=https://duepublico2.uni-due.de/servlets/MCRFileNodeServlet/duepublico_derivate_00073893/Diss_Weinrank.pdf#chapter.192>chapter 7 of Felix Weinrank&rsquo;s thesis</a>.</p><h2 id=a-quick-look-at-the-results-why-this-matters-if-you-dont-live-in-sctp-land>A quick look at the results (why this matters if you don&rsquo;t live in SCTP land)<a class=content-header-href href=#a-quick-look-at-the-results-why-this-matters-if-you-dont-live-in-sctp-land><i class="fas fa-paperclip"></i></a></h2><p><a href=https://github.com/pion/scp>SCP</a> is a Go test harness that runs two Pion SCTP stacks against each other inside a deterministic, in-process &ldquo;virtual network&rdquo; (from Pion/transport). It pins exact commits on each side, replays scenarios with a fixed seed, validates packet on the wire (CRC32c + basic SCTP parsing), and writes artifacts (<code>results.json</code>, packet logs, and pprof) so you can reproduce the numbers.</p><h3 id=the-headline-max-burst-more-throughput-less-cpu-lower-latency>The headline (max-burst): more throughput, less CPU, lower latency<a class=content-header-href href=#the-headline-max-burst-more-throughput-less-cpu-lower-latency><i class="fas fa-paperclip"></i></a></h3><p>This is the cleanest microbench in the suite: no loss, no delay, no jitter. Just a burst of messages in both directions. Comparing <strong>non-rack&lt;->non-rack</strong> vs <strong>rack&lt;->rack</strong> (There are similar improvements even when comparing <strong>rack&lt;->non-rack</strong>):</p><table><thead><tr><th>metric</th><th>main (baseline)</th><th>RACK</th><th>delta</th></tr></thead><tbody><tr><td>goodput</td><td>234.55 Mbps</td><td>316.42 Mbps</td><td><strong>+34.9%</strong></td></tr><tr><td>CPU time (<code>cpu_seconds</code>)</td><td>0.0560 s</td><td>0.0441 s</td><td><strong>âˆ’21.3%</strong></td></tr><tr><td>goodput / CPU-second</td><td>4,189</td><td>7,177</td><td><strong>+71.3%</strong></td></tr><tr><td>latency p50</td><td>16.37 ms</td><td>11.86 ms</td><td><strong>âˆ’27.5%</strong></td></tr><tr><td>latency p99</td><td>36.95 ms</td><td>27.84 ms</td><td><strong>âˆ’24.6%</strong></td></tr></tbody></table><p>That <strong>+71% throughput-per-CPU</strong> is simply the goodput measured (Mbps) divided by the run&rsquo;s <code>cpu_seconds</code>. Non-rack cruised at ~234 Mbps using ~0.056 CPU seconds (~4,189 Mbps/CPU-s), while RACK sustained 316 Mbps with ~0.044 CPU seconds (~7,177 Mbps/CPU-s). That gap is the proof that rack delivers ~71% more work per unit of CPU.</p><h3 id=test-setup>Test setup<a class=content-header-href href=#test-setup><i class="fas fa-paperclip"></i></a></h3><p>To test RACK, we ran these test profiles to compare how RACK performs against main (baseline):</p><ul><li><strong>max-burst</strong> - &ldquo;how fast can we go&rdquo; with no delay, loss, or reordering; it targets the raw transport path:</li></ul><p>Goodput jumps +34.9% (234 ->316â€¯Mbps) while CPU seconds drop by 21% (0.056 ->0.044â€¯s) and p50/p99 both fall by ~25%. RACK now delivers ~71% more Mbps per CPU-second.</p><ul><li><strong>handshake</strong> - same burst pattern, this time <strong>including</strong> the COOKIE/SHUTDOWN handshake, so we exercise setup timers:</li></ul><p>Goodput climbs +15% (237 ->272â€¯Mbps) while latency stays basically flat (15.65 ->15.99â€¯ms for p50, 35.27 ->33.25â€¯ms for p99), which confirms that the faster throughput comes without slower ACK paths.</p><ul><li><strong>unordered-late-low-rtt</strong> - minor delay/jitter (10â€¯ms) but unordered delivery to simulate packet trains with mild disorder:</li></ul><p>Minor latency and throughput noise. Both branches still pass but RACK keeps the delivery steady despite small unordered bursts.</p><ul><li><strong>unordered-late-high-rtt</strong> - large RTT/jitter (180â€¯ms / 60â€¯ms) with unordered delivery, so we can watch how the stack copes with latency spikes:</li></ul><p>Very high latency due to the profile, but RACK keeps throughput comparable while completely avoiding any regressions.</p><ul><li><strong>unordered-late-dynamic-rtt</strong> - fluctuating RTT (40â€¯ms base Â±180â€¯ms jitter) with unordered delivery to mimic burst-y network dynamics:</li></ul><p>Both branches pass with no noticeable regressions from RACK, which shows that each branch handles jitter swings fine.</p><ul><li><strong>congestion</strong> - ordered delivery with 2% loss and modest delay/jitter to stress-tests congestion control and SACK-driven recovery:</li></ul><p>The loss-handling path stays green and RACK doesn&rsquo;t use extra CPU compared to master which shows the +35% clean-case gain doesn&rsquo;t cost the loss profile.</p><ul><li><strong>retransmission</strong> - ordered with 5% loss and 20â€¯ms jitter to force fast-retransmit/TLP scenario:</li></ul><p>The fault case still hits retries and RACK&rsquo;s CPU profile actually shows more JSON/packet-logging work but that&rsquo;s what we expect during retransmit storms.</p><ul><li><strong>reorder-low</strong> - unordered with 1.5% loss plus deliberate reordering to exercise scheduler/queue behavior under lossï¼‹reorder:</li></ul><p>Goodput improves +44% (1.79 Mbps -> 2.58â€¯Mbps) and the run finishes faster (~3.70â€¯s vs 5.34â€¯s), so RACK dominates the low-rate reordering scenario.</p><ul><li><strong>burst-loss</strong> - unordered with 4% loss and 50â€¯ms jitter to push retransmit/recovery under heavy loss bursts.</li><li><strong>fragmentation</strong> - oversized payloads require chunk fragmentation/reassembly to verify large-message handling:</li></ul><p>Nothing improved or got worse.</p><ul><li><strong>media-hevc</strong> - A real-world use case with video: one-way stream, paced HEVC frames (~25â€¯fps), 3% loss, ~1200-byte max payload, across a ~13-14 Mbps link (taken from a real-world use case of sending DRM media over WebRTC datachannels) to ensure sustained media delivery works.</li></ul><p>RACK hits 12.90â€¯Mbps goodput in 2.14â€¯s (100% delivery) while the main branch streaming to the RACK branch sits at 11.34â€¯Mbps in 4.66â€¯s. That&rsquo;s a 2x faster finish!</p><p>We also have 3 negative tests to ensure that any corruptions or errors are still being caught:</p><ul><li><strong>fault-checksum</strong> - corrupts every 7th DATA chunk&rsquo;s checksum so receivers must drop it and log the error.</li><li><strong>fault-bad-chunk-len</strong> - mangles the chunk length field every 7th chunk to validate length checks/parsing.</li><li><strong>fault-nonzero-padding</strong> - corrupts padding bytes every 7th chunk so padding validation and chunk isolation logic are exercised.</li></ul><p>In both branches, these cases fail (as desired), which confirms that both branches detect the corruption and that there is no regression in behavior.</p><h3 id=cpu-flamegraphs>CPU flamegraphs<a class=content-header-href href=#cpu-flamegraphs><i class="fas fa-paperclip"></i></a></h3><p>The flamegraphs below show the CPU profiles for max-burst runs. You can see in the metadata that the RACK profile captured <strong>20ms of samples</strong> (9.95% of 201.08ms duration) versus the master profile&rsquo;s <strong>40ms of samples</strong> (19.86% of 201.45ms duration) â€“ exactly half the sample count for a similar duration, which directly supports the efficiency claims.</p><p><img src=/img/rack-cpu-master.svg alt="CPU Profile - Master"></p><p><img src=/img/rack-cpu-active.svg alt="CPU Profile - Rack"></p><h3 id=why-rack-behaves-better-not-just-goes-faster>Why RACK behaves better (not just &ldquo;goes faster&rdquo;)<a class=content-header-href href=#why-rack-behaves-better-not-just-goes-faster><i class="fas fa-paperclip"></i></a></h3><p>RACK changes <em>how</em> SCTP decides that something is lost and when it sends probes, so it wastes less work fixing problems that never really happened:</p><ul><li>Instead of keying almost everything off <strong>&ldquo;three missing reports or an RTO fired&rdquo;</strong>, RACK uses <strong>time-based loss detection</strong>: it looks at when chunks were last SACKed/ACKed and infers loss from elapsed time and the pattern of tail acknowledgments.</li><li><strong>Tail Loss Probes (TLP)</strong> send a cheap &ldquo;sample&rdquo; chunk at the end of a burst to flush out late ACKs. If the receiver really did get the data, it answers and the sender avoids a full retransmission storm, otherwise, the probe doubles as the retransmission you needed anyway.</li></ul><p>In practical terms that&rsquo;s what the profiles and metrics are showing:</p><ul><li>We still see the same hot stack (<code>vnet.(*chunkUDP).UserData</code>, <code>runtime.memmove</code>, a thin layer of runtime/type helpers) in both master and RACK. It&rsquo;s the normal packet I/O path.</li><li>With RACK, that stack is exercised <strong>fewer times per unit of useful data</strong> because there are fewer spurious retransmits and fewer &ldquo;just in case&rdquo; timer expirations.</li><li>That&rsquo;s exactly how we get <strong>more goodput, lower latency, and smaller CPU profiles at the same time</strong>: RACK spends less CPU &ldquo;arguing with the network&rdquo; and more CPU pushing real user data through SCTP.</li></ul><h3 id=spec-aligned-ack-behavior-and-testing>Spec-aligned ACK behavior and testing<a class=content-header-href href=#spec-aligned-ack-behavior-and-testing><i class="fas fa-paperclip"></i></a></h3><p>Using SCP testing tool we were able to find some issues includes:</p><ul><li><p>In the initial RACK implementation, handling of transitions from high to low RTT was suboptimal due to the implementation using a global minimum for recent RTT measurements instead of a windowed minimum (<a href=https://datatracker.ietf.org/doc/html/rfc8985#section-6.2-1>the latter approach is only a &ldquo;SHOULD&rdquo; in RFC 8985 section 6.2.1</a>). Atsushi Watanabe quickly identified it and we resolved the issue.</p></li><li><p>The earlier version of RACK implementation also handled packet reordering poorly and consumed more CPU than non-RACK. This was corrected by implementing improved active RTT measurement, following the approach described in <a href="https://duepublico2.uni-due.de/servlets/MCRFileNodeServlet/duepublico_derivate_00073893/Diss_Weinrank.pdf#page=120">Weinrank&rsquo;s work, see p. 120</a>.</p></li><li><p>A minor bug was discovered (and fixed) in the initial RACK implementation where the latest RTT was not measured for every packet.</p></li><li><p>We also found that Pion SCTP did not send a SACK immediately after a TSN gap, causing RACK to perform worse under moderate reordering. After fixing this behavior to align with <a href=https://datatracker.ietf.org/doc/html/rfc4960#section-6.7>RFC 4960 section 6.7 (surprisingly only a &ldquo;SHOULD&rdquo;)</a>, reordering test cases showed a ~30% improvement.</p></li></ul><h2 id=looking-forward>Looking forward<a class=content-header-href href=#looking-forward><i class="fas fa-paperclip"></i></a></h2><p>Keep an eye out for even more improvements and benchmarks from our improved SCTP implementation using real-world data, as well as how we&rsquo;re doing it in an upcoming blog post!</p><p>Thanks for reading!</p><h2 id=credits>Credits<a class=content-header-href href=#credits><i class="fas fa-paperclip"></i></a></h2><p>Huge thanks to the following for making this possible:</p><ul><li><a href=https://github.com/JoeTurki>Joe Turki</a> for introducing me to Pion, making SCP, answering countless questions, and so much more.</li><li><a href=https://github.com/Sean-Der>Sean DuBois</a> for making Pion, finding <a href=https://duepublico2.uni-due.de/servlets/MCRFileNodeServlet/duepublico_derivate_00073893/Diss_Weinrank.pdf>Felix Weinrank&rsquo;s thesis</a>, and endless encouragement.</li><li><a href=https://github.com/ValorZard>Srayan Jana</a> for helping to bounce around many ideas.</li><li><a href=https://github.com/at-wat>Atsushi Watanabe</a> for reviewing and catching the global minimum vs windowed minimum issue in the RACK PR.</li><li>And many more people along the way!</li></ul></div></section><footer class=footer><hr class=footer-hr><div class="content has-text-right"><p><a href=https://github.com/pion/website/blob/master/content/en/blog/sctp-and-rack.md target=_blank>Edit this page</a></p></div></footer></main><script type=module>
      import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.esm.min.mjs';
      mermaid.initialize({ startOnLoad: true });
    </script></body></html>